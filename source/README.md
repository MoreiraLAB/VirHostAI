### datasets.py
The script defines custom dataset classes that load, process, and manage protein-ligand interaction data. These classes are designed to support:
- Flexible Granularity: Datasets can be accessed at different levels (residues or chains).
- Data Splits: Supports train, validation, and test splits as specified in the dataset.
- Balanced Datasets: Additional support for balanced batch handling with the BalancedInteractionsDataset.

### torch_map.py
This script defines mappings for common activation functions, loss functions (criterions), and optimizers to streamline model configuration.

### transformations.py
This script defines several functions for managing and transforming datasets. It includes support for removing or updating specific dataset features, handling missing values, and rebalancing data through oversampling and SMOTE. Additionally, it logs each transformation, providing transparency and reproducibility.

There is no `__main__` function in this script. It is designed to be imported and used in other scripts for data transformation operations. We recommend using the provided transformations-logs to understand the transformations applied to the dataset-example.hdf5.

- `remove_clean(filepath: str, masks: dict = {}) -> None`: Cleans up the dataset by removing interactions, proteins, and ligands that are no longer valid or needed based on the provided masks. This is typically used to filter out entries with missing or invalid data.
- `remove_residues(original_filepath: str, transformed_filepath: str, value: float, features: Union[List[int], slice], any: bool = True) -> None`: Removes residues from the dataset based on specified feature values, such as NaN or Inf, updating the dataset accordingly. This helps in maintaining data integrity by excluding unreliable data points.
- `remove_chains(original_filepath: str, transformed_filepath: str, value: float, features: Union[List[int], slice], any: bool = True) -> None`: Removes protein chains from the dataset based on specified feature values, such as NaN or Inf, updating the dataset accordingly. This ensures that only valid and complete data is used for analysis.
- `remove_ligands(original_filepath: str, transformed_filepath: str, value: float, features: Union[List[int], slice], any: bool = True) -> None`: Removes ligands from the dataset based on specified feature values, such as NaN or Inf, updating the dataset accordingly. This is crucial for maintaining the quality of ligand data.
- `remove_protein_features(original_filepath: str, transformed_filepath: str, value: float, features: Union[List[int], slice], any: bool = True) -> None`: Removes specific protein features from the dataset based on specified values, such as NaN or Inf, updating the dataset accordingly. This helps in refining the dataset by excluding unreliable feature data.
- `remove_ligand_features(original_filepath: str, transformed_filepath: str, value: float, features: Union[List[int], slice], any: bool = True) -> None`: Removes specific ligand features from the dataset based on specified values, such as NaN or Inf, updating the dataset accordingly. This ensures that only valid ligand feature data is retained.
- `set_dtype(original_filepath: str, transformed_filepath: str, features: Optional[Type[np.dtype]] = None, targets: Optional[Type[np.dtype]] = None) -> None`: Sets the data type for features and targets in the dataset, updating the dataset accordingly. This is useful for ensuring consistency in data types across the dataset.
- `reduce_dimensionality_ae_proteins(original_filepath: str, transformed_filepath: str, model_filepath:str)`: Reduces the dimensionality of protein features using an autoencoder model, updating the dataset accordingly. This transformation helps in simplifying the dataset while retaining essential information.
- `sample_smote(original_filepath: str, transformed_filepath: str, residue_granularity: bool, batch_size: int, shuffle: bool = False, seed: int = 0)`: Applies SMOTE (Synthetic Minority Over-sampling Technique) to balance the dataset, creating synthetic samples for the minority class. This transformation results in a new dataset type called [BalancedInteractionsDataset](datasets.py#L314), which helps in addressing class imbalance.
- `sample_over(original_filepath: str, transformed_filepath: str, residue_granularity: bool, batch_size: int, shuffle: bool = False, seed: int = 0)`: Applies random oversampling to balance the dataset, duplicating samples from the minority class. This transformation also results in a new dataset type called [BalancedInteractionsDataset](datasets.py#L314), which is useful for mitigating class imbalance issues.